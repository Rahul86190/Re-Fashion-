{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27616, 2048)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "feature_list=np.array(pickle.load(open(\"new_embeddings.pkl\",\"rb\"))) # list converted into array\n",
    "filenames=pickle.load(open(\"new_filenames.pkl\",\"rb\"))\n",
    "\n",
    "print(np.array(feature_list).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50,preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= ResNet50(weights=\"imagenet\",include_top=False,input_shape=(224,224,3)) # we get weights that has trained on imagenet dataset\n",
    "model.trainable=False    # we are not going to train the model because we using the imagenet datset which is already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    model,     #pass the resnet50 model in sequential layer\n",
    "    GlobalMaxPooling2D()   # we added our layer globalmaxpooling2d instead of top layer . It gives 2048 features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n"
     ]
    }
   ],
   "source": [
    "img=image.load_img(\"sample/2977.jpg\",target_size=(224,224))  # i convert the image size in 224x224\n",
    "img_array=image.img_to_array(img)\n",
    "expand_img_array=np.expand_dims(img_array,axis=0)   # into betch\n",
    "preprocessed_img=preprocess_input(expand_img_array)\n",
    "result=model.predict(preprocessed_img).flatten()     # model give the features of the given image \n",
    "normalized_result=result/norm(result)   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to calculate nearest features \n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.        , 0.525823  , 0.62829387, 0.63947737, 0.64005429,\n",
       "         0.64180726, 0.64866257]]),\n",
       " array([[   73,    80, 21991,  9838,  8072,    43,  8094]], dtype=int64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbours=NearestNeighbors(n_neighbors=7,algorithm='brute',metric=\"euclidean\")\n",
    "neighbours.fit(feature_list)   \n",
    "neighbours.kneighbors([normalized_result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it give distance and indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   73    80 21991  9838  8072    43  8094]]\n"
     ]
    }
   ],
   "source": [
    "distance,indices=neighbours.kneighbors([normalized_result])\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000images\\2977.jpg\n",
      "10000images\\2978.jpg\n",
      "10000images\\57424.jpg\n",
      "10000images\\42394.jpg\n",
      "10000images\\3987.jpg\n",
      "10000images\\2974.jpg\n",
      "10000images\\3989.jpg\n"
     ]
    }
   ],
   "source": [
    "for file in indices[0]:\n",
    "    print(filenames[file])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in indices[0]:\n",
    "    pre_img=cv2.imread(filenames[file])\n",
    "    cv2.imshow(\"output\",cv2.resize(pre_img,(300,300),pre_img))\n",
    "    cv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
